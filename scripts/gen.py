#!/usr/bin/env python


import argparse
import ast
import json
import os
import re
import sys

import jsonpatch

# Python code generator to create new troposphere classes from the
# AWS resource specification.
#
# This gnerator works by reading in an AWS resource specification json file.
# The resources and properties are split apart to align with a given output
# file. In other words, a type such as AWS::Batch::JobDefinition will be
# put into the batch.py file.
#
# Since there are usually discrepencies in the docs or spec files plus the
# need for validation routines to be included there is additional processing
# done to the Resource Specification file and validators substituted into
# the code.
#
# For changes to the Resource Specification, there are jsonpatch files
# (located in scripts/patches) to fixup the json prior to emitting the code.
# A typical usage of this patch is when there is both a Resource and Property
# with the same name which cannot be emitted with the same class name. The
# jsonpatch file will usually rename the Property and then fixup any Resources
# using that Property.
#
# The validators are located in troposphere/validators with the common
# validators in __init__.py. This code generator will look for a corresponding
# file in this directory to locate validation functions. By parsing and walking
# the Python AST for this file it will extract function names and, based on a
# function docstring, will apply it as either a Property or Class validation
# function.
#
# Care is given to the output file to ensure pycodestyle and pyflakes tests
# will still pass. This incudes import declarations, class output ordering,
# and spacing considerations.
#
# Todo:
# - Currently only handles the single files (not the all-in-one)
#   (Note: but will deal with things like spec/GuardDuty*)
# - Handle adding in validators
# - Verify propery dependency/ordering in the file
# - Needs better error checking
# - Need to figure out the correct Timestamp type

stub = False

copyright_header = """\
# Copyright (c) 2012-2021, Mark Peek <mark@peek.org>
# All rights reserved.
#
# See LICENSE file for full license.
#
# *** Do not modify - this file is autogenerated ***
# Resource specification version: %s

"""
spec_version = ""


class Node:
    """Node object for building a per-file/service dependecy tree.

    Simple node object for creating and traversing the resource and
    property dependencies to emit code resources in a well-defined order.
    """

    def __init__(self, name, props, resource_name):
        self.name = name
        self.props = props
        self.resource_name = resource_name
        self.children = []

    def add_child(self, node):
        self.children.append(node)


class File:
    """Decribes a file object which contains resources for a given AWS service.

    The main output of this generator is a file containing all the property
    and resource classes for a given AWS service. This handles various needs
    such as imported objects, predictive ordering objects, and handling the
    type and validation overrides. The objects are mapped into the file
    based on the resource type.
    """

    def __init__(self, filename):
        self.filename = filename
        self.imports = {}
        self.properties = {}
        self.resources = {}
        self.resource_names = {}
        self.property_validators = []
        self.class_validators = {}

    def add_property(self, class_name, property_spec):
        self.properties[class_name] = property_spec

    def add_resource(self, class_name, resource_spec, resource_name):
        self.resources[class_name] = resource_spec
        self.resource_names[class_name] = resource_name

    def _check_type(self, check_type, properties):
        """Decode a properties type looking for a specific type."""
        if "PrimitiveType" in properties:
            return properties["PrimitiveType"] == check_type

        # If there's no Type defined, punt it for now...
        if "Type" not in properties:
            return False

        if properties["Type"] == "List":
            if "ItemType" in properties:
                return properties["ItemType"] == check_type
            else:
                return properties["PrimitiveItemType"] == check_type
        return False

    def _walk_for_type(self, check_type):
        """Walk the resources/properties looking for a specific type."""
        for class_name, properties in sorted(self.resources.items()):
            for key, value in sorted(properties.items()):
                if self._check_type(check_type, value):
                    return True
        for class_name, properties in sorted(self.properties.items()):
            for key, value in sorted(properties.items()):
                if self._check_type(check_type, value):
                    return True

        return False

    def _walk_for_key(self, check_key):
        """Walk the resources/properties looking for a specific key."""
        for class_name, properties in sorted(self.resources.items()):
            for key, value in sorted(properties.items()):
                if key == "Tags":
                    return True
        for class_name, properties in sorted(self.properties.items()):
            for key, value in sorted(properties.items()):
                if key == "Tags":
                    return True
        return False

    def _get_property_type(self, value):
        """Decode the values type and return a non-primitive property type."""
        if "PrimitiveType" in value:
            return None
        if "Type" not in value:
            return None
        if value["Type"] == "List":
            if "ItemType" in value:
                return value["ItemType"]
            else:
                return None
        elif value["Type"] == "Map":
            return None
        else:
            # Non-primitive (Property) name
            return value["Type"]

    def _get_type_list(self, props):
        """Return a list of non-primitive types used by this object."""
        type_list = []
        for k, v in list(props.items()):
            t = self._get_property_type(v)
            if t is not None:
                type_list.append(t)
        return sorted(type_list)

    def _output_imports(self):
        """Output common validator types based on usage."""
        if self.resources:
            print("from . import AWSObject")
        if self.properties:
            print("from . import AWSProperty")

        if self._walk_for_key("Tags"):
            print("from . import Tags")

        if self._walk_for_type("Boolean"):
            print("from .validators import boolean")
        if self._walk_for_type("Integer"):
            print("from .validators import integer")
        if self._walk_for_type("Double"):
            print("from .validators import double")

        for v in self.property_validators:
            print(f"from .validators.{self.filename} import {v}")
        for k, v in self.class_validators.items():
            print(f"from .validators.{self.filename} import {v}")

    def build_tree(self, name, props, resource_name=None):
        """Build a tree of non-primitive typed dependency order."""
        n = Node(name, props, resource_name)
        prop_type_list = self._get_type_list(props)
        if not prop_type_list:
            return n
        prop_type_list = sorted(prop_type_list)
        for prop_name in prop_type_list:
            if prop_name == "Tag":
                continue

            # prevent recursive properties
            if prop_name == name:
                continue

            child = self.build_tree(prop_name, self.properties[prop_name])
            if child is not None:
                n.add_child(child)
        return n

    def output_tree(self, t, seen):
        """Given a dependency tree of objects, output it in DFS order."""
        if not t:
            return
        for c in t.children:
            self.output_tree(c, seen)
        if t.name in seen:
            return
        seen[t.name] = True
        class_validator = self.class_validators.get(t.name, None)
        if stub:
            output_class_stub(t.name, t.props, class_validator)
            return
        if t.resource_name:
            output_class(t.name, t.props, class_validator, t.resource_name)
        else:
            output_class(t.name, t.props, class_validator)

    def _get_file_validators(self):
        try:
            validator_filename = f"troposphere/validators/{self.filename}.py"
            file_contents = open(validator_filename).read()
        except FileNotFoundError:
            return

        # Look for these patterns to match where to apply validation functions
        class_re = re.compile(r"^Class: ([\w]*)", re.MULTILINE)
        property_re = re.compile(r"^Property: ([\w]*)\.([\w]*)", re.MULTILINE)

        # Parse and walk the AST of the validation code file
        tree = ast.parse(file_contents)
        for node in ast.walk(tree):
            if isinstance(node, ast.FunctionDef):
                docstring = ast.get_docstring(node, clean=True)
                if docstring:
                    # Look for class level validation routines
                    r = class_re.search(docstring)
                    if r:
                        self.class_validators[r.group(1)] = node.name

                    # Look for property level validation routines
                    r = property_re.search(docstring)
                    if r:
                        # XXX - PrimitiveType, Type, or ItemType?
                        name = r.group(1)
                        property = r.group(2)
                        if name in self.resources:
                            self.resources[name][property]["PrimitiveType"] = node.name
                        elif name in self.properties:
                            self.properties[name][property]["PrimitiveType"] = node.name
                        self.property_validators.append(node.name)

    def output(self):
        """Output the generated source file."""
        self._get_file_validators()

        print(copyright_header % spec_version)
        self._output_imports()

        seen = {}
        for class_name, properties in sorted(self.resources.items()):
            resource_name = self.resource_names[class_name]
            t = self.build_tree(class_name, properties, resource_name)
            self.output_tree(t, seen)


class Resources:
    def __init__(self, resource_spec):
        self.files = {}

        for resource_name, resource_dict in sorted(
            resource_spec["ResourceTypes"].items()
        ):
            f = self._get_file(resource_name)
            class_name = resource_name.split(":")[4]
            properties = resource_dict["Properties"]
            f.add_resource(class_name, properties, resource_name)

        for property_name, property_dict in sorted(
            resource_spec["PropertyTypes"].items()
        ):
            if property_name == "Tag":
                continue
            f = self._get_file(property_name)
            class_name = property_name.split(".")[1]
            if "Properties" in property_dict:
                properties = property_dict["Properties"]
            else:
                properties = {}
            f.add_property(class_name, properties)

    def _filename_map(self, name):
        return name.split(":")[2].lower()

    def _get_file(self, aws_name):
        filename = self._filename_map(aws_name)
        if filename not in self.files:
            self.files[filename] = File(filename)
        return self.files[filename]

    def output_file(self, name):
        self.files[name].output()

    def output_files(self):
        for name, file in sorted(self.files.items()):
            file.output()


def get_required(value):
    return value["Required"]


map_type = {
    "Boolean": "boolean",
    "Double": "double",
    "Integer": "integer",
    "Json": "dict",
    "Long": "integer",
    "String": "str",
    "Timestamp": "str",
}


map_type3 = {
    "Boolean": "bool",
    "Double": "double",
    "Integer": "int",
    "Json": "dict",
    "Long": "int",
    "String": "str",
    "Timestamp": "str",
}


def get_type(value):
    if "PrimitiveType" in value:
        return map_type.get(value["PrimitiveType"], value["PrimitiveType"])

    if "Type" not in value:
        return "dict"

    if value["Type"] == "List":
        if "ItemType" in value:
            return "[%s]" % value["ItemType"]
        else:
            return "[%s]" % map_type.get(value["PrimitiveItemType"])
    elif value["Type"] == "Map":
        return "dict"
    else:
        # Non-primitive (Property) name
        return value["Type"]

    import pprint

    pprint.pprint(value)
    raise ValueError("get_type")


def get_type3(value):
    if "PrimitiveType" in value:
        return map_type3.get(value["PrimitiveType"], value["PrimitiveType"])
    if value["Type"] == "List":
        if "ItemType" in value:
            return "[%s]" % value["ItemType"]
        else:
            return "[%s]" % map_type3.get(value["PrimitiveItemType"])
    elif value["Type"] == "Map":
        return "dict"
    else:
        # Non-primitive (Property) name
        return value["Type"]

    import pprint

    pprint.pprint(value)
    raise ValueError("get_type")


def output_class(class_name, properties, class_validator, resource_name=None):
    print()
    print()
    if resource_name:
        print(f"class {class_name}(AWSObject):")
        print(f"    resource_type = '{resource_name}'")
        print()
    else:
        print(f"class {class_name}(AWSProperty):")

    # Output the props dict
    print("    props = {")
    for key, value in sorted(properties.items()):
        if key == "Tags":
            value_type = "Tags"
            if "PrimitiveType" in value and value["PrimitiveType"] == "Json":
                value_type = "dict"
        else:
            value_type = get_type(value)

        required = get_required(value)

        print(f'        "{key}": ({value_type}, {required}),')
    print("    }")
    if class_validator:
        print()
        print("    def validate(self):")
        print(f"       {class_validator}(self)")


def output_class_stub(class_name, properties, resource_name=None):
    print()
    print()
    if resource_name:
        print(f"class {class_name}(AWSObject):")
        print("    resource_type: str")
        print()
        sys.stdout.write("    def __init__(self, title")
    else:
        print(f"class {class_name}(AWSProperty):")
        print()
        sys.stdout.write("    def __init__(self")

    for key, value in sorted(properties.items()):
        if key == "Tags":
            value_type = "Tags"
        else:
            value_type = get_type3(value)

        if value_type.startswith("["):  # Means that args are a list
            sys.stdout.write(f", {key}:List{value_type}=...")
        else:
            sys.stdout.write(f", {key}:{value_type}=...")

    print(") -> None: ...")
    print()

    for key, value in sorted(properties.items()):
        if key == "Tags":
            value_type = "Tags"
        else:
            value_type = get_type3(value)

        if value_type.startswith("["):  # Means that args are a list
            print(f"    {key}: List{value_type}")
        else:
            print(f"    {key}: {value_type}")


def process_file(filename, stub=False):
    f = open(filename)
    j = json.load(f)

    if "PropertyTypes" in j:
        for property_name, property_dict in list(j["PropertyTypes"].items()):
            if property_name == "Tag":
                print("from . import Tags")
                print()
                continue
            class_name = property_name.split(".")[1]
            properties = property_dict["Properties"]
            if stub:
                output_class_stub(class_name, properties)
            else:
                output_class(class_name, properties)

    for resource_name, resource_dict in list(j["ResourceType"].items()):
        class_name = resource_name.split(":")[4]
        properties = resource_dict["Properties"]
        if stub:
            output_class_stub(class_name, properties, resource_name)
        else:
            output_class(class_name, properties, resource_name)


if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument("--stub", action="store_true", default=False)
    parser.add_argument("--name", action="store")
    parser.add_argument("filename", nargs="+")
    args = parser.parse_args()

    stub = args.stub

    f = open(args.filename[0])
    resource_spec = json.load(f)

    # Apply json patches
    patch_dir = "scripts/patches"
    for patch_file in os.listdir(patch_dir):
        if patch_file.endswith(".json"):
            patch = json.loads(open(os.path.join(patch_dir, patch_file)).read())
            resource_spec = jsonpatch.apply_patch(resource_spec, patch)

    spec_version = resource_spec["ResourceSpecificationVersion"]

    r = Resources(resource_spec)

    if args.name:
        r.output_file(args.name.lower())
    else:
        r.output_files()
